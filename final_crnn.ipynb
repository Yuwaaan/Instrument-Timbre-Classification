{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e94aa3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c6815d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0+cu113'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbe57175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)\n",
    "if_gpu = torch.cuda.is_available()  # whether available\n",
    "print(if_gpu)\n",
    "gpu_number = torch.cuda.current_device()\n",
    "print(gpu_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a00b993e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d79afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [ 0.05873846  0.05935711 -0.0090022  ... -0.1926996  -0.18709995\n",
      " -0.19382837]\n",
      "x.shape = (441000,)\n",
      "sr = 22050\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import torch\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "audio_path = \"./Testing/14.  Boots Randolph - Yakety Sax-1.wav\"\n",
    "\n",
    "\n",
    "x, sr = librosa.load(audio_path)\n",
    "print(f'x = {x}')\n",
    "print(f'x.shape = {x.shape}')\n",
    "print(f'sr = {sr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fb4eb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/banjo\n",
      "(74, 128, 22)\n",
      "/bass clarinet\n",
      "(545, 128, 22)\n",
      "/bassoon\n",
      "(313, 128, 22)\n",
      "/cello\n",
      "(660, 128, 22)\n",
      "/clarinet\n",
      "(906, 128, 22)\n",
      "/contrabassoon\n",
      "(605, 128, 22)\n",
      "/cor anglais\n",
      "(258, 128, 22)\n",
      "/double bass\n",
      "(622, 128, 22)\n",
      "/flute\n",
      "(452, 128, 22)\n",
      "/french horn\n",
      "(245, 128, 22)\n",
      "/gac\n",
      "(599, 128, 22)\n",
      "/gel\n",
      "(760, 128, 22)\n",
      "/guitar\n",
      "(29, 128, 22)\n",
      "/mandolin\n",
      "(60, 128, 22)\n",
      "/oboe\n",
      "(244, 128, 22)\n",
      "/org\n",
      "(676, 128, 22)\n",
      "/percussion\n",
      "(77, 128, 22)\n",
      "/pia\n",
      "(645, 128, 22)\n",
      "/saxophone\n",
      "(1107, 128, 22)\n",
      "/trombone\n",
      "(440, 128, 22)\n",
      "/trumpet\n",
      "(916, 128, 22)\n",
      "/tuba\n",
      "(555, 128, 22)\n",
      "/viola\n",
      "(147, 128, 22)\n",
      "/violin\n",
      "(1084, 128, 22)\n",
      "/voi\n",
      "(777, 128, 22)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('combine-22.h5', 'r') as f:\n",
    "# with h5py.File('LPOD-22.h5', 'r') as f:\n",
    "# with h5py.File('train_data_whole2.h5', 'r') as f:\n",
    "    for key in f.keys():\n",
    "        print(f[key].name)\n",
    "        print(f[key].shape)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee79b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dataset\n",
    "# keys = ['cel', 'cla', 'flu', 'gac', 'gel', 'org', 'pia', 'tru', 'voi', 'sax', 'vio']\n",
    "keys = ['banjo', 'bass clarinet', 'bassoon', 'cello', 'clarinet', 'contrabassoon', 'cor anglais', 'double bass', 'flute', 'french horn', 'guitar', 'mandolin', 'oboe', 'saxophone', 'trombone', 'trumpet', 'tuba', 'viola', 'violin']\n",
    "# keys = ['banjo','cel','cla','flute','french_horn','gac','gel','guitar', 'mandolin', 'oboe','org','percussion','pia','saxophone', 'trombone', 'trumpet','tuba', 'viola', 'violin']\n",
    "# dataset = h5py.File('LPOD-22.h5', 'r')\n",
    "dataset = h5py.File('combine-22.h5', 'r')\n",
    "# dataset = h5py.File('train_data_whole2.h5', 'r')\n",
    "\n",
    "num_of_labels = len(keys)  # 2\n",
    "num_of_tracks = sum([dataset[x].shape[0] for x in keys])  # 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92b9f8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9262, 128, 22)\n",
      "(9262, 19)\n",
      "(8335, 128, 22)\n",
      "(927, 128, 22)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for training and testing\n",
    "features = np.zeros((num_of_tracks, 128, 22), dtype=np.float32)   # (3, 128, 22)\n",
    "labels = np.zeros((num_of_tracks, len(keys)), dtype=np.float32)   # (3, 2)\n",
    "\n",
    "i = 0\n",
    "for ki, k in enumerate(keys):\n",
    "    features[i:i + len(dataset[k])] = np.nan_to_num(dataset[k])  # 使用0代替数组x中的nan元素\n",
    "    labels[i:i + len(dataset[k]), ki] = 1\n",
    "    i += len(dataset[k])\n",
    "\n",
    "print(features.shape) # (2, 128, 22)\n",
    "print(labels.shape)  # (2, 2)\n",
    "\n",
    "# Split trainset to train and evaluation\n",
    "# X_train,X_test, y_train, y_test = train_test_split(train_data,train_target,test_size=0.4, random_state=0)\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split(features, labels, test_size=0.1, random_state=1337)\n",
    "print(X_train.shape)\n",
    "print(X_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41f05b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.utils.data.dataset.TensorDataset'>\n"
     ]
    }
   ],
   "source": [
    "# Prepare Pytorch dataloader\n",
    "X_train_torch = torch.from_numpy(X_train).to(device)\n",
    "X_eval_torch = torch.from_numpy(X_eval).to(device)\n",
    "Y_train_torch = torch.from_numpy(Y_train).to(device)\n",
    "Y_eval_torch = torch.from_numpy(Y_eval).to(device)\n",
    "\n",
    "print(type(X_train_torch))\n",
    "\n",
    "trainset = torch.utils.data.TensorDataset(X_train_torch, Y_train_torch)\n",
    "evalset = torch.utils.data.TensorDataset(X_eval_torch, Y_eval_torch)\n",
    "\n",
    "print(type(trainset))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True, num_workers=0)\n",
    "eval_dataloader = torch.utils.data.DataLoader(evalset, batch_size=1, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e16848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Han16\n",
    "class Han16(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "        \n",
    "\t\tself.conv1_1 = nn.Conv2d(1, 32, 3, padding=2)\n",
    "\t\tself.conv1_2 = nn.Conv2d(32, 32, 3, padding=2)\n",
    "\t\tself.conv2_1 = nn.Conv2d(32, 64, 3, padding=2)\n",
    "\t\tself.conv2_2 = nn.Conv2d(64, 64, 3, padding=2)\n",
    "\t\tself.conv3_1 = nn.Conv2d(64, 128, 3, padding=2)\n",
    "\t\tself.conv3_2 = nn.Conv2d(128, 128, 3, padding=2)\n",
    "\t\tself.conv4_1 = nn.Conv2d(128, 256, 3, padding=2)\n",
    "\t\tself.conv4_2 = nn.Conv2d(256, 256, 3, padding=2)\n",
    "\t\tself.pool = nn.MaxPool2d(3, stride=3)\n",
    "\t\tself.zero_pad = nn.ZeroPad2d(1)\n",
    "\t\t# self.pool1 = nn.MaxPool2d(x.size(dim=2), x.size(dim=3))\n",
    "\t\tself.fc1 = nn.Linear(256, 1024)\n",
    "\t\tself.fc_output = nn.Linear(1024, num_of_labels)\n",
    "                \n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tif isinstance(m, nn.Conv2d):\n",
    "\t\t\t\tnn.init.xavier_normal_(m.weight)\n",
    "\t\t\t\tnn.init.constant(m.bias, 0)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = F.leaky_relu(self.conv1_1(self.zero_pad(x)))\n",
    "\t\tx = self.pool(F.leaky_relu(self.conv1_2(self.zero_pad(x)), negative_slope=0.33))\n",
    "\t\tx = F.dropout(x, p=0.25)\n",
    "\t\tx = F.leaky_relu(self.conv2_1(self.zero_pad(x)))\n",
    "\t\tx = self.pool(F.leaky_relu(self.conv2_2(self.zero_pad(x)), negative_slope=0.33))\n",
    "\t\tx = F.dropout(x, p=0.25)\n",
    "\t\tx = F.leaky_relu(self.conv3_1(self.zero_pad(x)))\n",
    "\t\tx = self.pool(F.leaky_relu(self.conv3_2(self.zero_pad(x)), negative_slope=0.33))\n",
    "\t\tx = F.dropout(x, p=0.25)\n",
    "\t\tx = F.leaky_relu(self.conv4_1(self.zero_pad(x)))\n",
    "\t\tx = F.leaky_relu(self.conv4_2(self.zero_pad(x)), negative_slope=0.33)\n",
    "\t\tx = F.max_pool2d(x, kernel_size=x.size()[2:]) # global max pooling\n",
    "\t\tx = x.view(-1, 256)\n",
    "\t\tx = F.leaky_relu(self.fc1(x), negative_slope=0.33)\n",
    "\t\tx = F.dropout(x, p=0.5)\n",
    "\t\tx = self.fc_output(F.sigmoid(x))\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "555e5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvBlocks + bilstm + Transformer\n",
    "class ConvBlocks(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(ConvBlocks, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1),padding=(1,1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1),padding=(1,1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1),padding=(1,1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128,128, kernel_size=(3, 3), stride=(1, 1),padding=(1,1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1,1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256,256, kernel_size=(3, 3), stride=(1, 1), padding=(1,1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1,1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1,1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512,512, kernel_size=(3, 3), stride=(1, 1), padding=(1,1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1,1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(kernel_size=(2,1), stride=(2,1)),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1),padding=(1,1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512,512, kernel_size=(3, 3), stride=(1, 1),padding=(1,1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1),padding=(1,1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(kernel_size=(2,1), stride=(2,1)),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1),padding=(1,1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512,512, kernel_size=(3, 3), stride=(1, 1),padding=(1,1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1),padding=(1,1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(kernel_size=(2,1), stride=(2,1)),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "\n",
    "        )\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        out = self.conv(inputs)\n",
    "        out = out.flatten(start_dim=1, end_dim=2)\n",
    "        return out\n",
    "   \n",
    "\n",
    " \n",
    "class Model(nn.Module):\n",
    "    def __init__(self,num_classes=9):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.conv = ConvBlocks()\n",
    "        self.blstm = nn.LSTM(1024, hidden_size=int(320/2),bidirectional=True, batch_first=True)\n",
    "#         self.mha = TransformerEncoderLayer(embed_dim=320, num_heads=10,temp=0.2)\n",
    "        self.fc1 = nn.Linear(320, 512)\n",
    "        self.fc2 = nn.Linear(512, self.num_classes)\n",
    "        self.fc3 = nn.Linear(1024, 320)\n",
    "        self.fc4 = nn.Linear(512, 320)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        cnn_out = self.conv(inputs)\n",
    "        cnn_out = cnn_out.permute(0,2,1)   \n",
    "\n",
    "        # bilstm layer\n",
    "        rnn_out,_ = self.blstm(cnn_out)\n",
    "        rnn_out = rnn_out.permute(1,0,2)\n",
    "#         print(rnn_out.shape)\n",
    "\n",
    "        \n",
    "#      # Transformer layer\n",
    "        rnn_out = self.fc3(cnn_out)   \n",
    "#         mha_out = self.mha(rnn_out)\n",
    "#         mha_out = mha_out.permute(1,0,2)\n",
    "        \n",
    "#         print(mha_out.shape)\n",
    "\n",
    "        \n",
    "        pooled = torch.mean(rnn_out, dim=1)\n",
    "        fc1_out = self.fc1(pooled)\n",
    "        out = self.fc2(fc1_out)\n",
    "        out = torch.sigmoid(out)\n",
    "#         print(out.shape) # torch.Size([1, 11])\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35fc5732",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\neko_maru~\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  5829] loss: 173.523\n",
      "[2,  5829] loss: 172.710\n",
      "[3,  5829] loss: 171.631\n",
      "[4,  5829] loss: 171.631\n",
      "[5,  5829] loss: 171.631\n",
      "[6,  5829] loss: 171.631\n",
      "[7,  5829] loss: 171.631\n",
      "[8,  5829] loss: 171.631\n",
      "[9,  5829] loss: 171.631\n",
      "[10,  5829] loss: 171.631\n",
      "[11,  5829] loss: 171.631\n",
      "[12,  5829] loss: 171.631\n",
      "[13,  5829] loss: 171.631\n",
      "[14,  5829] loss: 171.631\n",
      "[15,  5829] loss: 171.631\n",
      "[16,  5829] loss: 171.631\n",
      "[17,  5829] loss: 171.631\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NEKO_M~1\\AppData\\Local\\Temp/ipykernel_118492/2390781999.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0moptimiser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\neko_maru~\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\neko_maru~\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\neko_maru~\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m                    eps=group['eps'])\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\neko_maru~\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialisation\n",
    "# net = Net2()\n",
    "# net = ConvBlocks()\n",
    "# net = Model(19).to(device)\n",
    "net = Han16().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimiser = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "optimiser = optim.Adam(net.parameters(), lr=0.001)\n",
    "for epoch in range(25): \n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader, start=0):\n",
    "\n",
    "        inputs = inputs.unsqueeze(1) # add one dimension # torch.Size([1, 1, 128, 22])\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs) # torch.Size([1, 5])\n",
    "        _, labels = torch.max(labels, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i == len(train_dataloader)-1:  # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')\n",
    "PATH = './wave_model_han16net.pth'\n",
    "# PATH = './wave_model_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4dc120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(PATH))  # 将预训练的参数权重加载到新的模型之中\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(eval_dataloader, start=0):\n",
    "        inputs = inputs.unsqueeze(1) # add one dimension\n",
    "        outputs = net(inputs)\n",
    "        newlabels = labels > 0\n",
    "        indices =  newlabels.nonzero()     \n",
    "        print(outputs.data)\n",
    "        pred_sum = outputs.data.sum()\n",
    "        _, pred_max = torch.max(outputs.data, 1)\n",
    "        pred_max = outputs.data[0][pred_max]\n",
    "        print(pred_sum)\n",
    "        print(pred_max)\n",
    "        pred_index = outputs.data / pred_max\n",
    "        print(1)\n",
    "        print(pred_index)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        print(indices)\n",
    "        correct += (predicted == indices[0][1]).sum().item()\n",
    "        print('label:')\n",
    "        print(labels)\n",
    "        print('newlabel:')\n",
    "        print(indices[0][1])\n",
    "        print('predicted:')\n",
    "        print(predicted)        \n",
    "        print('Total: %d' % total)\n",
    "        print('Correct: %d' % correct)\n",
    "        \n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f719353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
